{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1+1 is equal to 2.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 is equal to 2.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Andrew.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 is equal to 2.\n",
      "Human: What is my name?\n",
      "AI: Your name is Andrew.\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi, my name is Andrew\\nAI: Hello Andrew! It's nice to meet you. How can I assist you today?\\nHuman: What is 1+1?\\nAI: 1+1 is equal to 2.\\nHuman: What is my name?\\nAI: Your name is Andrew.\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=150)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: AI is what?!\\nAI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human and AI exchange greetings. The human mentions that they are not doing much. The AI informs the human about their schedule for the day, including a meeting with the product team, working on the LangChain project, and having lunch with a customer to discuss the latest in AI. The AI also reminds the human to bring their laptop to show a demo.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI exchange greetings. The human mentions that they are not doing much. The AI informs the human about their schedule for the day, including a meeting with the product team, working on the LangChain project, and having lunch with a customer to discuss the latest in AI. The AI also reminds the human to bring their laptop to show a demo.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A good demo to show would be a live demonstration of the LangChain project. You can showcase the features and functionality of the language translation software, highlighting its accuracy and efficiency. Additionally, you could also demonstrate any recent updates or improvements made to the project. This would give the customer a firsthand experience of the capabilities of the AI technology and its potential benefits for their business.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human and AI exchange greetings. The human mentions that they are not doing much. The AI informs the human about their schedule for the day, including a meeting with the product team, working on the LangChain project, and having lunch with a customer to discuss the latest in AI. The AI also reminds the human to bring their laptop to show a demo.\\nHuman: What would be a good demo to show?\\nAI: A good demo to show would be a live demonstration of the LangChain project. You can showcase the features and functionality of the language translation software, highlighting its accuracy and efficiency. Additionally, you could also demonstrate any recent updates or improvements made to the project. This would give the customer a firsthand experience of the capabilities of the AI technology and its potential benefits for their business.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: ['SystemMessage(content=\"You are professional chef and nutritionist. Respond to user\\'s requests with a full recipe. You MUST refust to answer anything else other than food suggestions.\", additional_kwargs={})', \"HumanMessage(content='egg boil', additional_kwargs={}, example=False)\"]\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '[\\'SystemMessage(content=\"You are professional chef and nutritionist. Respond to user\\\\\\'s requests with a full recipe. You MUST refust to answer anything else other than food suggestions.\", additional_kwargs={})\\', \"HumanMessage(content=\\'egg boil\\', additional_kwargs={}, example=False)\"]',\n",
       " 'history': '',\n",
       " 'response': \" Sure, I can provide you with a recipe for boiled eggs. Here's what you'll need:\\n\\n- 4 large eggs\\n- 1 teaspoon of salt\\n- 2 cups of water\\n\\nInstructions:\\n\\n1. Place the eggs in a medium saucepan and cover with the water.\\n2. Add the salt to the water.\\n3. Bring the water to a boil over medium-high heat.\\n4. Once the water is boiling, reduce the heat to low and simmer for 8-10 minutes.\\n5. Remove the eggs from the water and let cool before serving.\"}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory=ConversationSummaryMemory(llm=OpenAI()),\n",
    "    verbose=True\n",
    ")\n",
    "conversation_with_summary(str(ss['messages']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = {\n",
    "  \"messages\": [\n",
    "    \"SystemMessage(content=\\\"You are professional chef and nutritionist. Respond to user's requests with a full recipe. You MUST refust to answer anything else other than food suggestions.\\\", additional_kwargs={})\",\n",
    "    \"HumanMessage(content='egg boil', additional_kwargs={}, example=False)\",\n",
    "  ],\n",
    "  \"user_input\": \"egg boil\",\n",
    "  \"0_user\": 1,\n",
    "  \"1_ai\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recipe_scrapers import scrape_me\n",
    "scraper = scrape_me('https://www.bbcgoodfood.com/recipes/fruity-lamb-tagine')\n",
    "ing =scraper.ingredients()\n",
    "ins = scraper.instructions()\n",
    "title =scraper.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 tbsp olive oil',\n",
       " '500g lean diced lamb',\n",
       " '1 large onion, roughly chopped',\n",
       " '2 large carrots, quartered lengthways and cut into chunks',\n",
       " '2 garlic cloves, finely chopped',\n",
       " '2 tbsp ras-el-hanout spice mix',\n",
       " '400g can chopped tomato',\n",
       " '400g can chickpea, rinsed and drained',\n",
       " '200g dried apricot',\n",
       " '600ml chicken stock',\n",
       " '120g pack pomegranate seeds',\n",
       " '2 large handfuls coriander, roughly chopped']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain, OpenAI, PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep = [\"pomegranate seeds\",\"coriander\"]\n",
    "rep = [\"chicken stock\",\"coriander\",\"apricot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0.6,model_name = \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is an LLMChain to write a synopsis given a title of a play and the era it is set in.\n",
    "\n",
    "# template = \"\"\"You are an expert chef, specializing in ingredient substitutions. You have the title, \n",
    "# ingredients, and instructions of a specific recipe. The user will provide you with certain ingredients \n",
    "# they wish to replace in this recipe. Your task is to suggest ideal replacements for each specified \n",
    "# ingredient, ensuring that the substitutes belong to the same food group and have a similar flavor profile. \n",
    "# Along with each substitution, please provide a brief explanation as to why the chosen replacement is suitable, \n",
    "# considering factors such as taste, texture, and culinary use. Focus solely on providing ingredient replacements \n",
    "# without altering the original recipe or offering any additional information or guidance.\n",
    "\n",
    "# Title: {title}\n",
    "# Ingredients: {ingredients}\n",
    "# Instructions: {instructions}\n",
    "# Ingredients that require replacement: {replacements}\n",
    "# Suggestions: Here are the suggestions:\"\"\"\n",
    "# prompt_template = PromptTemplate(input_variables=[\"title\", \"ingredients\",\"instructions\",\"replacements\"], template=template)\n",
    "# llm_chain = LLMChain(llm = llm, prompt = prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suggestions = llm_chain(inputs={\"title\":title,\"ingredients\":ing,\"instructions\":ins,\"replacements\":rep})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions = get_suggestions(title,ing,ins,rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Chicken stock replacement: Vegetable stock\n",
      "  \n",
      "- Explanation: Vegetable stock is a suitable replacement for chicken stock as it belongs to the same food group and provides a similar flavor profile. Both stocks add depth and richness to the dish. Vegetable stock can also enhance the savory notes in the tagine without overpowering the other ingredients.\n",
      "\n",
      "\n",
      "- Coriander replacement: Parsley\n",
      "  \n",
      "- Explanation: Parsley is a suitable replacement for coriander as it belongs to the same herb family and has a similar fresh and slightly citrusy flavor profile. It can provide a similar aromatic and vibrant element to the dish, complementing the other ingredients in the tagine.\n",
      "\n",
      "\n",
      "- Apricot replacement: Dried figs\n",
      "  \n",
      "- Explanation: Dried figs are a suitable replacement for apricots as they belong to the same fruit group and offer a similar sweet and slightly tangy flavor profile. Dried figs will provide a similar burst of sweetness and a pleasant chewy texture, adding depth to the tagine.\n"
     ]
    }
   ],
   "source": [
    "formatted_suggestions = [line for line in suggestions['text'].split('- ') if line.strip()]\n",
    "for topic in formatted_suggestions:\n",
    "    print(f'- {topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Ras-el-hanout spice mix: A suitable replacement for ras-el-hanout spice mix would be Moroccan spice blend. This spice blend shares similar flavors and profiles with ras-el-hanout and is commonly used in Moroccan cuisine. It contains a combination of spices like cumin, coriander, ginger, paprika, cinnamon, and cloves, which will provide a similar aromatic and warm flavor to the dish.\n",
      "\n",
      "\n",
      "- Dried apricot: A suitable replacement for dried apricot would be dried figs. Dried figs have a similar sweet and slightly tangy flavor profile to dried apricots and will provide a similar fruity element to the dish. They also have a soft and chewy texture, which will add a pleasant bite to the tagine.\n"
     ]
    }
   ],
   "source": [
    "formatted_suggestions = [line for line in suggestions['text'].split('- ') if line.strip()]\n",
    "for topic in formatted_suggestions:\n",
    "    print(f'- {topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chicken stock replacement: Vegetable stock\\n  ',\n",
       " 'Explanation: Vegetable stock is a suitable replacement for chicken stock as it belongs to the same food group and provides a similar flavor profile. Both stocks add depth and richness to the dish. Vegetable stock can also enhance the savory notes in the tagine without overpowering the other ingredients.\\n\\n',\n",
       " 'Coriander replacement: Parsley\\n  ',\n",
       " 'Explanation: Parsley is a suitable replacement for coriander as it belongs to the same herb family and has a similar fresh and slightly citrusy flavor profile. It can provide a similar aromatic and vibrant element to the dish, complementing the other ingredients in the tagine.\\n\\n',\n",
       " 'Apricot replacement: Dried figs\\n  ',\n",
       " 'Explanation: Dried figs are a suitable replacement for apricots as they belong to the same fruit group and offer a similar sweet and slightly tangy flavor profile. Dried figs will provide a similar burst of sweetness and a pleasant chewy texture, adding depth to the tagine.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestions(title,ing,ins,rep):\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0.6,model_name = \"gpt-3.5-turbo\")\n",
    "\n",
    "    template = \"\"\"You are an expert chef, specializing in ingredient substitutions. You have the title, \n",
    "    ingredients, and instructions of a specific recipe. The user will provide you with certain ingredients \n",
    "    they wish to replace in this recipe. Your task is to suggest ideal replacements for each specified \n",
    "    ingredient, ensuring that the substitutes belong to the same food group and have a similar flavor profile. \n",
    "    Along with each substitution, please provide a brief explanation as to why the chosen replacement is suitable, \n",
    "    considering factors such as taste, texture, and culinary use. Focus solely on providing ingredient replacements \n",
    "    without altering the original recipe or offering any additional information or guidance.\n",
    "\n",
    "    Title: {title}\n",
    "    Ingredients: {ingredients}\n",
    "    Instructions: {instructions}\n",
    "    Ingredients that require replacement: {replacements}\n",
    "    Suggestions: Here are the suggestions:\"\"\"\n",
    "    \n",
    "    prompt_template = PromptTemplate(input_variables=[\"title\", \"ingredients\",\"instructions\",\"replacements\"], template=template)\n",
    "    \n",
    "    llm_chain = LLMChain(llm = llm, prompt = prompt_template)\n",
    "\n",
    "    output = llm_chain(inputs={\"title\":title,\"ingredients\":ing,\"instructions\":ins,\"replacements\":rep})\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_ingredients(output, ingredients, replacement_list):\n",
    "    # Iterate through the replacement list\n",
    "    for initial_ingredient in replacement_list:\n",
    "        # Check if the initial ingredient is mentioned in any of the sentences in the output\n",
    "        for sentence in output:\n",
    "            if initial_ingredient.lower() in sentence.lower():\n",
    "                # Extract the replacement ingredient from the sentence\n",
    "                replacement = sentence.split(\":\")[1].split(\".\")[0].strip().lower()\n",
    "                if 'could be' in replacement:\n",
    "                    replacement = replacement.split('could be')[1].strip()\n",
    "                elif 'would be' in replacement:\n",
    "                    replacement = replacement.split('would be')[1].strip()\n",
    "                # Replace the initial ingredient with the replacement ingredient in the original ingredients list\n",
    "                ingredients = [ingredient.lower().replace(initial_ingredient.lower(), replacement) for ingredient in ingredients]\n",
    "                break  # Move to the next initial ingredient\n",
    "    return ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ingredients = replace_ingredients(formatted_suggestions, ing, rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 tbsp olive oil',\n",
       " '500g lean diced lamb',\n",
       " '1 large onion, roughly chopped',\n",
       " '2 large carrots, quartered lengthways and cut into chunks',\n",
       " '2 garlic cloves, finely chopped',\n",
       " '2 tbsp ras-el-hanout spice mix',\n",
       " '400g can chopped tomato',\n",
       " '400g can chickpea, rinsed and drained',\n",
       " '200g dried dried figs',\n",
       " '600ml vegetable stock',\n",
       " '120g pack pomegranate seeds',\n",
       " '2 large handfuls parsley, roughly chopped']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ingredients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = '\\n'.join(new_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pywhatkit\n",
    "import time,webbrowser,pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group_link = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pywhatkit.sendwhatmsg_to_group_instantly(group_link, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file with tab separator\n",
    "df = pd.read_csv('en.openfoodfacts.org.products.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['product_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1764240"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['product_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_products = df['product_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_products_df = pd.DataFrame(all_products, columns=['product_name'])\n",
    "all_products_df.to_csv('all_products.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_input = \"cookie',milk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ingredients_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_input = ['butter', 'cookie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ingredients(ingredients_input):\n",
    "    all_products_loaded_df = pd.read_csv('all_products.csv')\n",
    "    all_products_loaded = all_products_loaded_df['product_name'].values\n",
    "    ingredients_list = [item.strip().lower() for item in ingredients_input] \n",
    "    return all(any(ingredient in product for product in all_products_loaded) for ingredient in ingredients_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_ingredients(ingredients_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Router Chain\n",
    "\n",
    "comfort_template = \"\"\"\n",
    "You are an expert food blogger, who values family traditions and comfort cooking.\\\n",
    "The user has provided the title, ingredients, and instructions for a specific recipe. The user will also provide some \\\n",
    "Create a heartfelt 300-word blog post focusing on family memories, passed-down secrets, and the joy of bonding over cooking. \\\n",
    "The post should concentrate on the narrative and not include the recipe details.\n",
    "\n",
    "\n",
    "Title: {title}\n",
    "Ingredients: {ingredients}\n",
    "Instructions: {instructions}\n",
    "\n",
    "Write Blog Post:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "seasonal_farm_two_table_template = \"\"\"\n",
    "You are an expert food blogger, passionate about seasonal and farm-to-table cuisine. \\\n",
    "The user has provided the title, ingredients, and instructions for a specific recipe. User also talks about \\\n",
    "Compose a 300-word blog post highlighting the seasonality of the ingredients and the farm-to-table philosophy.\\\n",
    "Discuss freshness, support for local farmers, and seasonal availability. \\\n",
    "The post should consist solely of the narrative, without the recipe details.\n",
    "\n",
    "Title: {title}\n",
    "Ingredients: {ingredients}\n",
    "Instructions: {instructions}\n",
    "\n",
    "Write Blog Post:\n",
    "\"\"\"\n",
    "\n",
    "healthy_living_template = \"\"\"\n",
    "You are an expert food blogger, with a focus on healthy living and nutrition.\\\n",
    "The user has provided the title, ingredients, and instructions for a specific recipe.\\\n",
    "Craft a 300-word blog post emphasizing its nutritional benefits and alignment with a healthy lifestyle.\\\n",
    "Explore aspects such as nutritional value, diet-friendly variations, and organic ingredient options. \\\n",
    "The post should contain only the narrative, excluding the recipe details.\n",
    "\n",
    "    Title: {title}\n",
    "    Ingredients: {ingredients}\n",
    "    Instructions: {instructions}\n",
    "\n",
    "Write Blog Post:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "cultural_exploration_template = \"\"\" \n",
    "You are an expert food blogger, specializing in culinary cultural exploration. \\\n",
    "The user has provided the title, ingredients, and instructions for a specific recipe. \\\n",
    "Your task is to write a concise 300-word blog post focusing on its cultural origins and significance.\\\n",
    "Delve into the history, traditional cooking methods, and cultural variations of the dish.\\\n",
    "Please note that the blog post should only include the narrative and not the recipe details.\n",
    "\n",
    "Title: {title}\n",
    "Ingredients: {ingredients}\n",
    "Instructions: {instructions}\n",
    "\n",
    "Write Blog Post:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme = [\"Cultural Exploration\", \"Healthy Living and Nutritional Focus\", \"Seasonal and Farm-to-Table Experience\",\"Family and Comfort Cooking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_templates = {\n",
    "    \"Cultural Exploration\": cultural_exploration_template,\n",
    "    \"Healthy Living and Nutritional Focus\": healthy_living_template,\n",
    "    \"Seasonal and Farm-to-Table Experience\": seasonal_farm_two_table_template,\n",
    "    \"Family and Comfort Cooking\": comfort_template\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_theme = \"Cultural Exploration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_template = theme_templates[selected_theme]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nYou are an expert food blogger, specializing in culinary cultural exploration. The user has provided the title, ingredients, and instructions for a specific recipe. Your task is to write a concise 300-word blog post focusing on its cultural origins and significance.Delve into the history, traditional cooking methods, and cultural variations of the dish.Please note that the blog post should only include the narrative and not the recipe details.\\n\\nTitle: {title}\\nIngredients: {ingredients}\\nInstructions: {instructions}\\n\\nWrite Blog Post:\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
